{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>15313</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB NAME = NISHANT:CUSTOMER_DETAILS\n",
      "No_of_cpu=8\n",
      "Max_cores=8\n",
      "Executor_mem=56g"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# runtype = \"daily\"\n",
    "# report_date = \"2021-02-28\" #automated\n",
    "\n",
    "no_of_cpu = 8\n",
    "max_cores = 8\n",
    "executor_mem = '56g'\n",
    "\n",
    "\n",
    "Job_Name = 'NISHANT:CUSTOMER_DETAILS'\n",
    "\n",
    "\n",
    "# print \"JOB NAME = \"+str(Job_Name)\n",
    "# print \"No_of_cpu=\"+str(no_of_cpu)\n",
    "# print \"Max_cores=\"+str(max_cores)\n",
    "# print \"Executor_mem=\"+str(executor_mem)\n",
    "# print \"Runtype=\"+str(runtype)\n",
    "# print \"Report_date=\"+str(report_date)\n",
    "\n",
    "\n",
    "print (\"JOB NAME = \"+str(Job_Name))\n",
    "print (\"No_of_cpu=\"+str(no_of_cpu))\n",
    "print (\"Max_cores=\"+str(max_cores))\n",
    "print (\"Executor_mem=\"+str(executor_mem))\n",
    "# print (\"Runtype=\"+str(runtype))\n",
    "# print (\"Report_date=\"+str(report_date))\n",
    "\n",
    "\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.sql.functions import asc,lit\n",
    "#warnings.filterwarnings('error')\n",
    "import pyspark\n",
    "from datetime import datetime,timedelta\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "#import numpy\n",
    "import calendar\n",
    "#import pandas as pd\n",
    "#import simplejson as json\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import lit\n",
    "import simplejson as json\n",
    "import json, pprint, requests\n",
    "#es_nodes = '10.35.12.5'\n",
    "#es_nodes = '10.35.12.6'\n",
    "# es_nodes = '10.35.12.194'#,10.35.12.6,10.35.12.5\n",
    "# es_nodes_temp='10.35.12.194'\n",
    "# es_port = '5432'\n",
    "# es_user = 'gpanalytics'\n",
    "# es_pwd = ''\n",
    "mesos_ip = 'mesos://10.33.195.18:5050'#'mesos://10.35.12.5:5050'\n",
    "spark.stop() #############NEED TO COMMENT THIS SPARK.STOP WHEN RUNNING THROUGH SHELL###############################\n",
    "conf.setMaster(mesos_ip)\n",
    "\n",
    "conf.set('spark.executor.cores',no_of_cpu) ### change\n",
    "#conf.set('spark.memory.fraction','.2')\n",
    "conf.set('spark.executor.memory',executor_mem) \n",
    "conf.set('spark.es.scroll.size','10000')\n",
    "conf.set('spark.network.timeout','600s')\n",
    "conf.set('spark.sql.crossJoin.enabled', 'true')\n",
    "conf.set('spark.sql.join.preferSortMergeJoin','true')\n",
    "\n",
    "conf.set('spark.ui.port','4052')\n",
    "\n",
    "conf.set('spark.executor.heartbeatInterval','60s')\n",
    "conf.set(\"spark.driver.cores\",\"4\")\n",
    "conf.set(\"spark.driver.extraJavaOptions\",\"-Xmx4g -Xms4g\")\n",
    "\n",
    "#conf.set(\"spark.shuffle.blockTransferService\", \"nio\"); \n",
    "conf.set(\"spark.files.overwrite\",\"true\");\n",
    "conf.set(\"spark.kryoserializer.buffer\", \"70\"); \n",
    "conf.set(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\");\n",
    "conf.set(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\");\n",
    "conf.set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\"); \n",
    "#conf.set(\"spark.broadcast.compress\", \"true\"); \n",
    "conf.set(\"spark.shuffle.compress\", \"true\"); \n",
    "conf.set(\"spark.shuffle.spill.compress\", \"true\");\n",
    "conf.set(\"spark.app.name\", Job_Name)\n",
    "#conf.set(\"spark.io.compression.codec\",\"org.apache.spark.io.LZ4CompressionCodec\");\n",
    "#conf.set(\"spark.sql.inMemoryColumnarStorage.compressed\", \"true\"); \n",
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "conf.set('spark.driver.memory','20g') ### change 2\n",
    "conf.set('spark.cores.max',max_cores) ### change 3\n",
    "conf.set('spark.sql.shuffle.partitions','400')\n",
    "#conf.set('spark.sql.crossJoin.enabled', 'true')\n",
    "# conf.set('es.nodes',es_nodes)\n",
    "# conf.set('es.port',es_port)\n",
    "# conf.set('es.nodes.wan.only','true')\n",
    "conf.set(\"spark.sql.autoBroadcastJoinThreshold\",-1)\n",
    "\n",
    "#conf.set('spark.es.net.http.auth.user','Spark')\n",
    "#conf.set('spark.es.net.http.auth.pass','Jarkpet1Sap3')\n",
    "conf.set('spark.num.executors','4')\n",
    "\n",
    "# conf.set('spark.es.net.http.auth.user', es_user)\n",
    "# conf.set('spark.es.net.http.auth.pass', es_pwd)\n",
    "\n",
    "conf.set('spark.es.mapping.date.rich','false')\n",
    "spark = pyspark.SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "# Load Data into PySpark DataFrames\n",
    "# Prodcom Data Frame\n",
    "import json, pprint, requests\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2023-11-27 09:50:25.739710'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hash\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType\n",
    "import psycopg2\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import pytz\n",
    "starttime = time.time()\n",
    "start_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prod_url = \"jdbc:postgresql://10.35.12.194:5432/gpadmin\"\n",
    "prod_host = '10.35.12.194'\n",
    "prod_port = '5432'\n",
    "prod_dbname = 'gpadmin'\n",
    "user_prod=\"gpspark\"\n",
    "pwd_prod=\"spark@456\"\n",
    "dbschema=\"public\"\n",
    "\n",
    "\n",
    "prod_gpdb_spark_options ={\n",
    "    \"url\": \"jdbc:postgresql://{host}:{port}/{dbname}\".format(host=prod_host,port=prod_port, dbname=prod_dbname),\n",
    "    \"user\": \"{user}\".format(user=user_prod),\n",
    "    \"password\": \"{password}\".format(password=pwd_prod)\n",
    "} \n",
    "\n",
    "# Define the GPDB-Python connection options for PROD \n",
    "import psycopg2\n",
    "import datetime\n",
    "conn_prod = psycopg2.connect(host=prod_host, port=prod_port, user=user_prod, password=pwd_prod, dbname=prod_dbname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def load_gpdb_jdbc(col_str,dbtable,dbschema='public',col_name=None,time_filter=None,partitionColumn=\"row_num\"):\n",
    "    \"\"\"\n",
    "    This is used to read gpdb with filter for columns and can apply other filter(date,values).\n",
    "    Time filter contains startdate,enddate\n",
    "    \"\"\"\n",
    "    gscPythonOptions = {\n",
    "                        \"url\": prod_url,\n",
    "                        \"user\": user_prod,\n",
    "                        \"password\": pwd_prod,\n",
    "                        \"dbschema\": dbschema,\n",
    "                        \"dbtable\": dbtable,\n",
    "                        \"partitionColumn\":partitionColumn,\n",
    "                        \"partitions\": 8,\n",
    "                        \"server.port\":\"1150-1170\"}\n",
    "   \n",
    "    if time_filter:\n",
    "        data = sqlContext.read.format(\"greenplum\").options(**gscPythonOptions).load()\\\n",
    "                .selectExpr(col_str).drop_duplicates().filter(col(col_name).between(to_timestamp(lit(time_filter['start_date']),\n",
    "                                                                 format='yyyy-MM-dd'),\n",
    "                                                    to_timestamp(lit(time_filter['end_date']),\n",
    "                                                                 format='yyyy-MM-dd')))\n",
    "    else :\n",
    "        data = sqlContext.read.format(\"greenplum\").options(**gscPythonOptions).load()\\\n",
    "                .selectExpr(col_str).drop_duplicates()\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_latest_progress():\n",
    "    \n",
    "    try: \n",
    "        gscPythonOptions = {\n",
    "                 \"url\":prod_url ,\n",
    "                 \"user\":user_prod ,\n",
    "                 \"password\": pwd_prod,\n",
    "                 \"dbschema\":\"customermart\",\n",
    "                 \"dbtable\": \"progress\",#table change\n",
    "                 \"server.port\":\"1150-1170\"} \n",
    "\n",
    "        list_tn=['customer_profile123','customer_demographics123']\n",
    "        \n",
    "        # this query will fetch till what date we have inserted the records in target\n",
    "        last_run= sqlContext.read.format(\"greenplum\").options(**gscPythonOptions).load()\\\n",
    "            .select('table_name','source','to_datetime').filter(col('table_name').isin(list_tn))\n",
    "#         .filter(col('table_name')=='header')\\\n",
    "#             .filter(col('source')=='header')\n",
    "        \n",
    "        max_df=last_run.groupBy(\"table_name\").agg(max(\"to_datetime\").alias(\"datetime\"))\n",
    "        \n",
    "        Max_last_run =max_df.select(min('datetime')).first()[0]\n",
    "\n",
    "\n",
    "        # if no record is available in progress then it will raise value error, in this case default value will be picked from except clause\n",
    "        if Max_last_run is None:\n",
    "            raise ValueError(\"No records found!\")\n",
    "\n",
    "        #print(\"Record Found. Progress updated till {}\".format(Max_last_run))\n",
    "\n",
    "    except Exception as E: \n",
    "        Max_last_run = datetime.datetime(2018, 10, 30, 0, 0)  # this is the default start date when no record is present in progress for customer_demographics table\n",
    "        print(\"Executed_except\",repr(E))\n",
    "    return Max_last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generic function to save the progress from last run into Progress table\n",
    "def update_progress(table_name,source,time_filter,records,start_time,starttime,status):\n",
    "    output_index = \"progress\"\n",
    "    schema = \"customermart\"\n",
    "\n",
    "\n",
    "    import sys\n",
    "    import time\n",
    "    try:\n",
    "        \n",
    "\n",
    "\n",
    "        df_progress= sqlContext.createDataFrame([(table_name,source,\n",
    "                                       time_filter['start_date'].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                                         time_filter['end_date'].strftime(\"%Y-%m-%d %H:%M:%S\"),records)]\n",
    "                                     ,['table_name', 'source','from_datetime','to_datetime','records'])\\\n",
    "        .withColumn('start_time',lit(start_time)).withColumn('end_time',current_timestamp())\\\n",
    "                    .withColumn('executed_in_mins',lit((time.time() - starttime)/60))\\\n",
    "                                .withColumn('status',lit(status)).withColumn('remarks',lit(None))\n",
    "    \n",
    "\n",
    "        \n",
    "        df_progress.write.format(\"greenplum\")\\\n",
    "            .option(\"dbtable\",output_index).option('dbschema',schema)\\\n",
    "            .option(\"server.port\",\"1150-1170\").option(\"url\",prod_url)\\\n",
    "            .option(\"user\", user_prod).option(\"password\",pwd_prod).mode('append').save()\n",
    "        \n",
    "       \n",
    "    except Exception as e:\n",
    "        x = e\n",
    "        print(x)\n",
    "    else:\n",
    "        x = 'success'\n",
    "        print(\"Updated Progress for {table_name} from {source} until {to_datetime}. {records} records processed in this run\".format(table_name=table_name, source=source,to_datetime=time_filter['end_date'].strftime(\"%Y-%m-%d %H:%M:%S\"),records=records))\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Generic update function which takes the records currently in temp table (created with prefix 1 to original customercoe table)\n",
    "# The function would first try to insert the records in original table. It that fails then it will upsert the records\n",
    "# Since there is no direct upsert query an update and insert query with where clause is used\n",
    "# This funciton just runs the SQL queries in GPDB and does not use spark\n",
    "\n",
    "def update(conn_to,table_name,source,gpdb_spark_options = prod_gpdb_spark_options,\n",
    "                  schema=\"customermart\"):\n",
    "    conn_to.rollback()\n",
    "    primary_key = 'golden_id'\n",
    "    \n",
    "    # out columns are those columns that will be inserted into target table from temp table\n",
    "    out_columns = ['golden_id','name_prefix','first_name','middle_name','last_name','full_name','language_preferred',\n",
    "                   'language_spoken','birth_date','gender','marital_status','wedding_anniversary','nationality','occupation',\n",
    "                   'educational_qualification','gross_annual_income','ckyc','kyc_id','kyc_verfication_flag','kyc_datetime_stamp',\n",
    "                   'senior_citizen','height_cm','weight_kg',\n",
    "                   'tobacco_use_indicator','alcohol_use_indicator','credit_score_source','credit_score','customer_type','last_updated']\n",
    "\n",
    "    cur_to = conn_to.cursor()  \n",
    "\n",
    "    # this query insert records from temp table to target table when all the records in temp table are new and not present in target\n",
    "    only_insert_query = \"\"\"insert into {schema}.{table_name} ({out_columns})\n",
    "                                   select golden_id, name_prefix, first_name, middle_name, last_name, full_name, \n",
    "                                   language1,language1||','||language2||','||language3||','||language4,\n",
    "                                   birth_date, gender, marital_status, wedding_anniversary, nationality, occupation,\n",
    "                                   educational_qualification, gross_annual_income, ckyc,kyc_id,kyc_verfication_flag,kyc_datetime_stamp,senior_citizen, height_cm,\n",
    "                                   weight_kg, tobacco_use_indicator, alcohol_use_indicator,credit_score_source,credit_score,customer_type,last_updated from {schema}.{table_name}_staging \"\"\".format(schema=schema,table_name=table_name,out_columns = \",\".join(out_columns))\n",
    "    \n",
    "    # this query will be executed to update the records that are already present in target, new values will be assigned from temp table    \n",
    "    update_query = \"\"\"UPDATE {schema}.{table_name} orig\n",
    "                          SET\n",
    "                            name_prefix = temp.name_prefix,\n",
    "                            first_name = temp.first_name,\n",
    "                            middle_name = temp.middle_name,\n",
    "                            last_name = temp.last_name,\n",
    "                            language_preferred = temp.language1,\n",
    "                            language_spoken = temp.language1||','||temp.language2||','||temp.language3||','||temp.language4,\n",
    "                            birth_date = temp.birth_date,\n",
    "                            gender = temp.gender,\n",
    "                            marital_status = temp.marital_status,\n",
    "                            wedding_anniversary = temp.wedding_anniversary,\n",
    "                            nationality = temp.nationality,\n",
    "                            occupation = temp.occupation,\n",
    "                            educational_qualification = temp.educational_qualification,\n",
    "                            gross_annual_income = temp.gross_annual_income,\n",
    "                            ckyc=temp.ckyc,\n",
    "                            kyc_id=temp.kyc_id,\n",
    "                            kyc_verfication_flag=temp.kyc_verfication_flag,\n",
    "                            kyc_datetime_stamp=temp.kyc_datetime_stamp,\n",
    "                            senior_citizen = temp.senior_citizen,\n",
    "                            height_cm = temp.height_cm,\n",
    "                            weight_kg = temp.weight_kg,\n",
    "                            tobacco_use_indicator = temp.tobacco_use_indicator,\n",
    "                            alcohol_use_indicator = temp.alcohol_use_indicator,\n",
    "                            credit_score_source = temp.credit_score_source,\n",
    "                            credit_score = temp.credit_score,\n",
    "                            customer_type=temp.customer_type,\n",
    "                            last_updated = temp.last_updated\n",
    "                          FROM\n",
    "                            {schema}.{table_name}_staging temp\n",
    "                           WHERE \n",
    "                            orig.golden_id = temp.golden_id\n",
    "                       \"\"\".format(schema=schema,table_name=table_name)\n",
    "    \n",
    "    # this query will be executed after update query to insert the remaining records    \n",
    "    insert_query = \"\"\" INSERT INTO {schema}.{table_name} ({out_columns})\n",
    "                           SELECT  golden_id, name_prefix, first_name, middle_name, last_name, full_name, \n",
    "                                   language1,language1||','||language2||','||language3||','||language4,\n",
    "                                   birth_date, gender, marital_status, wedding_anniversary, nationality, occupation,\n",
    "                                   educational_qualification, gross_annual_income,ckyc,kyc_id,kyc_verfication_flag,kyc_datetime_stamp,senior_citizen, height_cm,\n",
    "                                   weight_kg, tobacco_use_indicator, alcohol_use_indicator,credit_score_source,credit_score,customer_type,last_updated\n",
    "                           FROM\n",
    "                             {schema}.{table_name}_staging temp\n",
    "                           WHERE\n",
    "                             NOT EXISTS (\n",
    "                             SELECT 1 FROM {schema}.{table_name} orig WHERE \n",
    "                             orig.golden_id = temp.golden_id\n",
    "                            )\n",
    "                        \"\"\".format(schema=schema,table_name=table_name,out_columns = \",\".join(out_columns))\n",
    "\n",
    "    try:\n",
    "        print(\"Inside try segment\")\n",
    "        cur_to.execute(only_insert_query)\n",
    "        print(\"Executed Only insert query\")\n",
    "#         update_progress(table_name,source,time_filter,records)\n",
    "    except Exception as e:\n",
    "        print(\"Inside except segment\")\n",
    "        conn_to.rollback()\n",
    "        cur_to.execute(update_query)\n",
    "        print(\"Executed update query\")\n",
    "        cur_to.execute(insert_query)\n",
    "        print(\"Executed insert query\")\n",
    "#         update_progress(table_name,source,time_filter,records)\n",
    "    conn_to.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed_except ValueError('No records found!')\n",
      "{'start_date': datetime.datetime(2018, 10, 30, 0, 0), 'end_date': datetime.datetime(2023, 11, 26, 0, 0)}"
     ]
    }
   ],
   "source": [
    "latest_progress=get_latest_progress()\n",
    "# dates in string format\n",
    "str_d1 = latest_progress.strftime(\"%Y-%m-%d\")\n",
    "str_d2 = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# convert string to date object\n",
    "d1 = datetime.datetime.strptime(str_d1, \"%Y-%m-%d\")\n",
    "d2 = datetime.datetime.strptime(str_d2, \"%Y-%m-%d\")\n",
    "\n",
    "# difference between dates in timedelta\n",
    "delta = d2 - d1\n",
    "day=delta.days-1 #currently T-2 change 2 to 1 for T-1\n",
    "\n",
    "# Executed_except ValueError('No records found!')\n",
    "# {'start_date': datetime.datetime(2018, 10, 30, 0, 0), 'end_date': datetime.datetime(2023, 9, 25, 0, 0)}\n",
    "\n",
    "time_filter={'start_date':latest_progress,'end_date':latest_progress+datetime.timedelta(days=day)}\n",
    "time_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# master_bulk_df=load_gpdb_jdbc(col_str,\"mastercraft_bulk_detail_prod\",\"dc_action_date\",time_filter)\n",
    "\n",
    "col_str=['dc_unified_id','source_customer_id','dc_action_date']\n",
    "\n",
    "master_bulk_df=load_gpdb_jdbc(col_str,\"mastercraft_bulk_detail_prod\",\"public\",\"dc_action_date\",time_filter)\n",
    "master_bulk_df=master_bulk_df.filter((col('dc_unified_id').isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201570037"
     ]
    }
   ],
   "source": [
    "master_bulk_df.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "master_bulk_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Demogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Demogs Begins"
     ]
    }
   ],
   "source": [
    "print('Customer Demogs Begins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# master_bulk_df=load_gpdb_jdbc(col_str,\"mastercraft_bulk_detail_prod\",\"dc_action_date\",time_filter)\n",
    "col_str=['dc_unified_id','title','first_name','middle_name','last_name','extractedname','bhv_language_primary',\\\n",
    "        'bhv_language_secondary','bhv_language_third','bhv_language_comm','birth_date','gender',\\\n",
    "       'anniversary_date','nationality','occupation','edu_highest_education','emp_annual_income','dc_active_flag']\n",
    "\n",
    "\n",
    "master_prod_df=load_gpdb_jdbc(col_str,\"mastercraft_master_prod\")\n",
    "master_prod_df=master_prod_df.filter((col('dc_unified_id').isNotNull()))\\\n",
    ".filter((col('dc_active_flag')==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_bulk_df=master_bulk_df.select('dc_unified_id','dc_action_date','source_customer_id')\n",
    "\n",
    "master_bulk_df= master_bulk_df.join(master_prod_df,'dc_unified_id',\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dc_unified_id', 'dc_action_date', 'source_customer_id', 'title', 'first_name', 'middle_name', 'last_name', 'extractedname', 'bhv_language_primary', 'bhv_language_secondary', 'bhv_language_third', 'bhv_language_comm', 'birth_date', 'gender', 'anniversary_date', 'nationality', 'occupation', 'edu_highest_education', 'emp_annual_income', 'dc_active_flag']"
     ]
    }
   ],
   "source": [
    "master_bulk_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr \n",
    "\n",
    "master_bulk_df=master_bulk_df.withColumn(\"title\",expr(\"case                     \\\n",
    "    when title = 'ADV' then 'Adv'                      \\\n",
    "    when title = 'BRIG' then 'Brig'                    \\\n",
    "    when title = 'CAPT' then 'Capt'                    \\\n",
    "    when title = 'CDR' then 'Cdr'                      \\\n",
    "    when title = 'COL' then 'Col'                      \\\n",
    "    when title = 'CUST' then 'Cust'                    \\\n",
    "    when title = 'DR' then 'Dr'                        \\\n",
    "    when title = 'GEN' then 'Gen'                      \\\n",
    "    when title = 'HON' then 'Hon'                      \\\n",
    "    when title = 'JUSTICE' then 'Justice'              \\\n",
    "    when title = 'LADY' then 'Lady'                    \\\n",
    "    when title = 'LT' then 'Lt'                        \\\n",
    "    when title = 'MAJ' then 'Maj'                      \\\n",
    "    when title = 'MAJOR' then 'Major'                  \\\n",
    "    when title in ('MAST','MASTER') then 'Mast'        \\\n",
    "    when title = 'MD' then 'Md'                        \\\n",
    "    when title = 'MIS' then 'Mis'                      \\\n",
    "    when title = 'MISS' then 'Miss'                    \\\n",
    "    when title = 'MR' then 'Mr'                        \\\n",
    "    when title = 'MRS' then 'Mrs'                      \\\n",
    "    when title = 'MS' then 'Ms'                        \\\n",
    "    when title = 'MST' then 'Mst'                      \\\n",
    "    when title = 'MSTR' then 'Mstr'                    \\\n",
    "    when title = 'PHD' then 'Phd'                      \\\n",
    "    when title in ('PROF','PROFF') then 'Prof'         \\\n",
    "    when title = 'REV' then 'Rev'                      \\\n",
    "    when title = 'SHRI' then 'Shri'                    \\\n",
    "    when title = 'SIST' then 'Sist'                    \\\n",
    "    when title = 'UNKNOWN' then 'Unknown'              \\\n",
    "    when title = 'WING CDR' then 'Wing Cdr'            \\\n",
    "    when title = 'WING COMMANDER' then 'Wing Commander'\\\n",
    "    else null end as title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_bulk_df=master_bulk_df.withColumn(\"gender\",expr(\"case                   \\\n",
    "    when gender in ('MALE','M') then 'MALE'                 \\\n",
    "    when gender in ('FEMALE','F') then 'FEMALE'             \\\n",
    "    when gender in ('COMPANYSOCIETY') then 'COMPANY/SOCIETY'\\\n",
    "    when gender in ('NOT SPECIFIED') then 'NOT SPECIFIED'   \\\n",
    "    else null end as gender\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "master_bulk_df=master_bulk_df.withColumn(\"educational_qualification\",expr(\"case                                        \\\n",
    "    when edu_highest_education = 'B A GRADUATE' then 'B A Graduate'                                \\\n",
    "    when edu_highest_education = 'B COM GRADUATE' then 'B Com Graduate'                            \\\n",
    "    when edu_highest_education = 'B E/B TECH GRADUATE' then 'B E/B Tech Graduate'                  \\\n",
    "    when edu_highest_education = 'B SC GRADUATE' then 'B Sc Graduate'                              \\\n",
    "    when edu_highest_education = 'CA/CS PROFESSIONAL' then 'CA/CS Professional'                    \\\n",
    "    when edu_highest_education = 'GRADUATE' then 'Graduate'                                        \\\n",
    "    when edu_highest_education = 'HIGH SCHOOL' then 'High School'                                  \\\n",
    "    when edu_highest_education = 'HSC HIGH SCHOOL' then 'HSC High School'                          \\\n",
    "    when edu_highest_education = 'LL.B PROFESSIONAL' then 'LL.B Professional'                      \\\n",
    "    when edu_highest_education = 'M A POST GRADUATE' then 'M A Post Graduate'                      \\\n",
    "    when edu_highest_education = 'M COM POST GRADUATE' then 'M Com Post Graduate'                  \\\n",
    "    when edu_highest_education = 'M E/M TECH POST GRADUATE' then 'M E/M Tech Post Graduate'        \\\n",
    "    when edu_highest_education = 'M SC POST GRADUATE' then 'M Sc Post Graduate'                    \\\n",
    "    when edu_highest_education = 'MBA/PGDM POST GRADUATE' then 'MBA/PGDM Post Graduate'            \\\n",
    "    when edu_highest_education = 'MBBS PROFESSIONAL' then 'MBBS Professional'                      \\\n",
    "    when edu_highest_education = 'OTHER' then 'Other'                                              \\\n",
    "    when edu_highest_education = 'OTHER DIPLOMA DIPLOMA' then 'Other Diploma Diploma'              \\\n",
    "    when edu_highest_education = 'OTHER GRADUATE GRADUATE' then 'Other Graduate Graduate'          \\\n",
    "    when edu_highest_education = 'OTHER OTHER' then 'Other Other'                                  \\\n",
    "    when edu_highest_education = 'OTHER POSTGRAD POST GRADUATE' then 'Other Postgrad Post Graduate'\\\n",
    "    when edu_highest_education = 'OTHER PROF PROFESSIONAL' then 'Other Prof Professional'          \\\n",
    "    when edu_highest_education = 'OTHER SCHOOL HIGH SCHOOL' then 'Other School High School'        \\\n",
    "    when edu_highest_education = 'PH D DOCTORAL' then 'Ph D Doctoral'                              \\\n",
    "    when edu_highest_education = 'POST GRADUATE' then 'Post Graduate'                              \\\n",
    "    when edu_highest_education = 'PROFESSIONAL' then 'Professional'                                \\\n",
    "    when edu_highest_education = 'SSC HIGH SCHOOL' then 'SSC High School'\\\n",
    "    else null end as educational_qualification\")).alias(\"educational_qualification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_bulk_df=master_bulk_df.withColumn(\"birth_date\",expr(\"case\\\n",
    "    when birth_date is not null and substring(birth_date,1,4) < '1922' then null\\\n",
    "    when birth_date is not null and substring(birth_date,1,4) > '2023' then null\\\n",
    "    when birth_date is not null then cast(concat(substring(birth_date,1,4),'-', substring(birth_date,6,2),'-', substring(birth_date,9,2)) as date)\\\n",
    "    else null end as birth_date\")).alias(\"birth_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# current_year=master_prod_df.select(year(current_date()).alias(\"current_year\")).collect()[0][\"current_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_bulk_df=master_bulk_df.withColumn(\"birth_date\",when(col('birth_date')=='1990-01-01',None).otherwise(col('birth_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql_context=SQLContext(spark)\n",
    "current_year=sql_context.sql(\"select year(current_date()) as current_year\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "master_bulk_df=master_bulk_df.withColumn(\"senior_citizen\", when(year(master_bulk_df.birth_date).cast('int')<1922,None)\\\n",
    "                                 .when(year(master_bulk_df.birth_date).cast('int')>current_year,None)\\\n",
    "                                 .when(((months_between(current_date(),master_bulk_df.birth_date)/lit(12)).cast('int') >=60),True)\\\n",
    "                                 .otherwise(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "master_bulk_df = master_bulk_df.withColumn('other_name_or_alias', lit(None).cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_str=['customer_code','txt_kyc_id','txt_kyc_verfication_flag','txt_ckyc','txt_datetime_stamp','ind_corp_flag','marital_status']\n",
    "cust_gc_df=load_gpdb_jdbc(col_str,\"customer_gc_genmst_customer\")\n",
    "\n",
    "cust_gc_df_type=cust_gc_df.selectExpr('customer_code','ind_corp_flag as customer_type','marital_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_str=['alcoholintake','panmasalaintake','num_reference_number']\n",
    "under_writing_dh_df=load_gpdb_jdbc(col_str,\"underwriting_dh_cnfgtr_otherdt_grid_tab_hlt\")\n",
    "under_writing_dh_df=under_writing_dh_df.filter((col('alcoholintake').isNotNull()) | (col('panmasalaintake').isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the data  from policy_gc_gen_prop_information_tab Table\n",
    "col_str=['txt_customer_id','num_reference_number']\n",
    "policy_gen_prop_df=load_gpdb_jdbc(col_str,\"policy_gc_gen_prop_information_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_str=['num_height_cm','num_height_feet','num_height_inch','num_weight','num_reference_number','2 as rnk']\n",
    "underwriting_gc_df2=load_gpdb_jdbc(col_str,\"underwriting_gc_uw_memberdetails\")\n",
    "underwriting_gc_df2=underwriting_gc_df2.withColumn('num_height_cm',when(col('num_height_cm')=='0',lit(None)).otherwise(col('num_height_cm')))\\\n",
    ".withColumn('num_height_feet',when(col('num_height_feet')=='0',lit(None)).otherwise(col('num_height_feet')))\\\n",
    ".withColumn('num_weight',when(col('num_weight')=='0',lit(None)).otherwise(col('num_weight')))\n",
    "\n",
    "underwriting_gc_df2=underwriting_gc_df2.filter((col('num_height_cm').isNotNull()) | (col('num_height_feet').isNotNull())\\\n",
    "                                             | (col('num_height_inch').isNotNull()) | (col('num_weight').isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_str=['height_of_insured_cm as num_height_cm','height_of_insured_feet as num_height_feet','height_of_insured_inches as num_height_inch'\n",
    "         ,'weight_of_insured_kg as num_weight','reference_num as num_reference_number','1 as rnk']\n",
    "underwriting_gc_df_1=load_gpdb_jdbc(col_str,\"policy_dh_risk_details_hlt\")\n",
    "\n",
    "underwriting_gc_df_1=underwriting_gc_df_1.withColumn('num_height_cm',when(col('num_height_cm')=='0',lit(None)).otherwise(col('num_height_cm')))\\\n",
    ".withColumn('num_height_feet',when(col('num_height_feet')=='0',lit(None)).otherwise(col('num_height_feet')))\\\n",
    ".withColumn('num_weight',when(col('num_weight')=='0',lit(None)).otherwise(col('num_weight')))\n",
    "\n",
    "underwriting_gc_df_1=underwriting_gc_df_1.filter((col('num_height_cm').isNotNull()) | (col('num_height_feet').isNotNull())\\\n",
    "                                             | (col('num_height_inch').isNotNull()) | (col('num_weight').isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "underwriting_gc_df=underwriting_gc_df_1.union(underwriting_gc_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w1 = Window.partitionBy('num_reference_number').orderBy(desc_nulls_last('num_height_cm'),desc_nulls_last('num_weight'),desc_nulls_last('rnk'))\n",
    "underwriting_gc_df = underwriting_gc_df.withColumn('row_num',F.row_number().over(w1))\n",
    "underwriting_gc_df = underwriting_gc_df.filter('row_num == 1').drop(underwriting_gc_df.rnk).drop(underwriting_gc_df.row_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gscPythonOptions = {\n",
    "         \"url\": prod_url,\n",
    "         \"user\": user_prod,\n",
    "         \"password\": pwd_prod,\n",
    "         \"dbschema\":\"datamarts\",\n",
    "         \"dbtable\": \"credit_bureau_data\",\n",
    "         \"server.port\":\"1150-1170\"} \n",
    "\n",
    "# Get the data  from credit_bureau_data Table\n",
    "\n",
    "credit_bureau_df = sqlContext.read.format(\"greenplum\").options(**gscPythonOptions).load()\\\n",
    ".select('dc_unified_id','source','score').dropDuplicates()\n",
    "\n",
    "credit_bureau_df = credit_bureau_df.withColumn('CIBIL_SCORE', F.regexp_replace('score', r'^[0]*', ''))\\\n",
    "                                    .withColumn(\"CIBIL_SCORE\", regexp_replace('CIBIL_SCORE', '\\..*$', ''))\\\n",
    "                                    .withColumn('CIBIL_SCORE',when(col('CIBIL_SCORE')=='-1',lit(\"NA\"))\n",
    "                                 .otherwise(col('CIBIL_SCORE')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Added new logic for KYC IPDS\n",
    "\n",
    "df_kyc= master_bulk_df.join(cust_gc_df, master_bulk_df.source_customer_id == cust_gc_df.customer_code, \"inner\")\\\n",
    ".selectExpr('dc_unified_id','txt_kyc_id as kyc_id','txt_kyc_verfication_flag as kyc_verfication_flag','txt_ckyc as ckyc',\n",
    "            'txt_datetime_stamp as kyc_datetime_stamp')\n",
    "\n",
    "df_kyc1=df_kyc.withColumn(\"kyc_verfication_flag\",expr(\"case\\\n",
    "    when lower(kyc_verfication_flag) in ('true') then '1'\\\n",
    "    when lower(kyc_verfication_flag) in ('false') then '0'\\\n",
    "    else null end as kyc_verfication_flag\"))\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w1 = Window.partitionBy('dc_unified_id').orderBy(desc_nulls_last('ckyc'),desc_nulls_last('kyc_id'),desc_nulls_last('kyc_datetime_stamp'))\n",
    "df_kyc1 = df_kyc1.withColumn('row_num',F.row_number().over(w1))\n",
    "df_kyc1 = df_kyc1.filter('row_num == 1')\n",
    "\n",
    "\n",
    "# df_kyc1=df_kyc.groupBy('dc_unified_id').agg(max(\"txt_kyc_id\").alias(\"kyc_id\"),max(\"txt_ckyc\").alias(\"ckyc\"),\\\n",
    "#                                max('txt_kyc_verfication_flag').alias(\"kyc_verfication_flag\"),max('txt_datetime_stamp').alias(\"kyc_datetime_stamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_1= master_bulk_df.join(cust_gc_df_type, master_bulk_df.source_customer_id == cust_gc_df_type.customer_code, \"left_outer\")\\\n",
    ".drop(cust_gc_df_type.customer_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_2= df_1.join(policy_gen_prop_df, df_1.source_customer_id == policy_gen_prop_df.txt_customer_id, \"left_outer\")\\\n",
    ".drop(policy_gen_prop_df.txt_customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_3= df_2.join(under_writing_dh_df, df_2.num_reference_number == under_writing_dh_df.num_reference_number, \"left_outer\")\\\n",
    ".drop(under_writing_dh_df.num_reference_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_4=df_3.join(underwriting_gc_df, df_3.num_reference_number == underwriting_gc_df.num_reference_number, \"left_outer\")\\\n",
    ".drop(underwriting_gc_df.num_reference_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5= df_4.join(credit_bureau_df, df_4.dc_unified_id == credit_bureau_df.dc_unified_id, \"left_outer\")\\\n",
    ".drop(credit_bureau_df.dc_unified_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_5=df_5.withColumn(\"height_cm\",when(col('num_height_cm').isNotNull() | col('num_height_cm')!='0',col('num_height_cm'))\\\n",
    "#                      .when(col('num_height_cm').isNull() | col('num_height_cm')=='0',coalesce((col('num_height_feet')*30+col('num_height_inch')*2.54).cast(float),0))\\\n",
    "#                      .otherwise(col('num_height_cm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_5=df_5.withColumn(\"height_cm\",expr(\"case when num_height_cm is not null or num_height_cm != '0' then num_height_cm\\\n",
    "                                      when (num_height_cm is null or num_height_cm!='0') and num_height_feet is not null then \\\n",
    "    coalesce(cast(num_height_feet as float)*30,0) + coalesce(cast(num_height_inch as float)*2.54,0)\\\n",
    "    else null end as height_cm\")).alias(\"height_cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5=df_5.withColumn(\"alcohol_use_indicator\",expr(\"case when alcoholintake in ('Occasionally','Monthly','Weekly','Daily') \\\n",
    "                                         then true else false end as alcohol_use_indicator\")).alias(\"alcohol_use_indicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5=df_5.withColumn(\"tobacco_use_indicator\",expr(\"case when panmasalaintake in ('Occasionally','Monthly','Weekly','Daily')\\\n",
    "                                        then true else false end as tobacco_use_indicator\")).alias(\"tobacco_use_indicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5 = df_5.withColumnRenamed('dc_unified_id','golden_id').\\\n",
    "withColumnRenamed('title','name_prefix').\\\n",
    "withColumnRenamed('extractedname','full_name').\\\n",
    "withColumnRenamed('bhv_language_primary','language1').\\\n",
    "withColumnRenamed('bhv_language_secondary','language2').\\\n",
    "withColumnRenamed('bhv_language_third','language3').\\\n",
    "withColumnRenamed('bhv_language_comm','language4').\\\n",
    "withColumnRenamed('anniversary_date','wedding_anniversary').\\\n",
    "withColumnRenamed('emp_annual_income','gross_annual_income').\\\n",
    "withColumnRenamed('source','credit_score_source').\\\n",
    "withColumnRenamed('score','credit_score').\\\n",
    "withColumnRenamed('dc_action_date','last_updated').\\\n",
    "withColumnRenamed('num_weight','weight_kg').\\\n",
    "withColumn(\"insert_date\",current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_5=df_5.withColumn('language_preferred', col('language1').cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_main= df_5.join(df_kyc1, df_5.golden_id == df_kyc1.dc_unified_id, \"left_outer\")\\\n",
    ".drop(df_kyc1.dc_unified_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_main=df_main.select(col('golden_id').cast('integer'),col('name_prefix').cast('string'),col('first_name').cast('string'),col('middle_name').cast('string'),col('last_name').cast('string'),col('full_name').cast('string'),col('other_name_or_alias').cast('string'),\n",
    "                       col('language1').cast('string'),col('language2').cast('string'),col('language3').cast('string'),col('language4').cast('string'),col('birth_date').cast(DateType()),col('gender').cast('string'),col('marital_status').cast('string'),\n",
    "                       col('wedding_anniversary').cast('string'),col('nationality').cast('string'),col('occupation').cast('string'),col('educational_qualification').cast('string'),col('gross_annual_income').cast(DoubleType()),\n",
    "                       col('ckyc').cast('string'),col('kyc_id').cast('string'),col('kyc_verfication_flag').cast('integer'),col('kyc_datetime_stamp').cast('timestamp'),col('senior_citizen').cast('boolean'),col('height_cm').cast('double'),col('weight_kg').cast('double'),col('alcohol_use_indicator').cast('boolean'),col('tobacco_use_indicator').cast('boolean'),\n",
    "                       col('credit_score_source').cast('string'),col('credit_score').cast('string'),col('last_updated').cast('timestamp'),col('customer_type').cast('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_main=df_main.withColumn('marital_status',when(col('marital_status').isin('Unknown','1951','--SELECT--','UNKNOWN'),lit('-'))\n",
    "                          .when(col('marital_status').isin('TRUE','Married','\"MARRIED \"','M'),lit('Married'))\\\n",
    "                          .when(col('marital_status').isin('Single','0','S','SINGLE'),lit('Unmarried'))\n",
    "                          .when(col('marital_status').isin('WIDOWED','W'),lit('Widow'))\n",
    "                          .when(lower(trim(col(\"marital_status\"))).rlike(\"\\\\s\"),lit('Married')).otherwise(col('marital_status')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w1 = Window.partitionBy('golden_id').orderBy(F.col('last_updated').desc())\n",
    "df_main = df_main.withColumn('row_num',F.row_number().over(w1))\n",
    "df_main = df_main.filter('row_num == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_main=df_main.select('golden_id', 'name_prefix', 'first_name', 'middle_name', 'last_name', 'full_name', 'other_name_or_alias', 'language1', 'language2', 'language3', 'language4', 'birth_date', 'gender', 'marital_status', 'wedding_anniversary', 'nationality', 'occupation', 'educational_qualification', 'gross_annual_income', 'ckyc', 'kyc_id', 'kyc_verfication_flag', 'kyc_datetime_stamp', 'senior_citizen', 'height_cm', 'weight_kg', 'alcohol_use_indicator', 'tobacco_use_indicator', 'credit_score_source', 'credit_score', 'last_updated', 'customer_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101002719"
     ]
    }
   ],
   "source": [
    "df_main.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "records=df_main.count()\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|height_cm|weight_kg|\n",
      "+---------+---------+\n",
      "|   182.88|     95.0|\n",
      "+---------+---------+"
     ]
    }
   ],
   "source": [
    "df_main.select('height_cm', 'weight_kg').filter(col('golden_id')=='121142284').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200"
     ]
    }
   ],
   "source": [
    "output_index = \"customer_demographics_staging\"\n",
    "schema = \"customermart\"\n",
    "\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    \n",
    "    df_main.write.option(\"truncate\", \"true\").format(\"greenplum\")\\\n",
    "    .option(\"dbtable\",output_index).option('dbschema',schema)\\\n",
    "    .option(\"server.port\",\"1150-1170\").option(\"url\",prod_url)\\\n",
    "    .option(\"user\", user_prod).option(\"password\",pwd_prod).mode('overwrite').save()\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    x = e\n",
    "    print(x)\n",
    "else:\n",
    "    x = 200 #success\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pg import DB\n",
    "# db = DB(dbname=\"gpadmin\", user='gpspark', passwd='spark@456', host='10.35.12.194', port= 5432)\n",
    "# GidCount = db.query(\"select count(*) from customermart.customer_demographics_staging\").getresult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name='customer_demographics'\n",
    "source='customer_demographics'\n",
    "conn_prod = psycopg2.connect(host=prod_host, port=prod_port, user=user_prod, password=pwd_prod, dbname=prod_dbname)\n",
    "conn_to=conn_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    update(conn_to,table_name,source,prod_gpdb_spark_options, schema=\"customermart\")\n",
    "except Exception as e:\n",
    "    x = e\n",
    "    print(x)\n",
    "else:\n",
    "    x = 'success'\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gscPythonOptions = {\n",
    "#          \"url\": prod_url,\n",
    "#          \"user\": user_prod,\n",
    "#          \"password\": pwd_prod,\n",
    "#          \"dbtable\": \"customermart.customer_demographics\",\n",
    "#          \"server.port\":\"1150-1170\"}\n",
    "\n",
    "\n",
    "# demog_df = sqlContext.read.format(\"jdbc\").options(**gscPythonOptions).load()\\\n",
    "# .select('golden_id','name_prefix','first_name','middle_name','last_name','full_name','birth_date','gender','marital_status','wedding_anniversary','nationality','occupation','gross_annual_income',\n",
    "# 'ckyc','kyc_id','kyc_verfication_flag','kyc_datetime_stamp','senior_citizen','height_cm','weight_kg','tobacco_use_indicator','alcohol_use_indicator','credit_score_source',\n",
    "# 'credit_score','last_updated')\\\n",
    "# .filter(col('last_updated').between(to_timestamp(lit(time_filter['start_date']),\n",
    "#                                                                  format='yyyy-MM-dd'),\n",
    "#                                                     to_timestamp(lit(time_filter['end_date']),\n",
    "#                                                                  format='yyyy-MM-dd'))).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_stag=df_main.select('golden_id','name_prefix','first_name','middle_name','last_name','birth_date','gender','marital_status','wedding_anniversary','nationality','occupation','gross_annual_income','ckyc','kyc_id','kyc_verfication_flag','kyc_datetime_stamp','senior_citizen',col('height_cm').cast('double'),col('weight_kg').cast('double'),\n",
    "#                    'tobacco_use_indicator','alcohol_use_indicator','credit_score_source','credit_score','last_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demog_df1=demog_df.select('golden_id','name_prefix','first_name','middle_name','last_name','birth_date','gender','marital_status','wedding_anniversary','nationality','occupation','gross_annual_income','ckyc','kyc_id','kyc_verfication_flag','kyc_datetime_stamp','senior_citizen',col('height_cm').cast('double'),col('weight_kg').cast('double'),\n",
    "#                    'tobacco_use_indicator','alcohol_use_indicator','credit_score_source','credit_score','last_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_MissingData=df_stag.exceptAll(demog_df1).withColumn('DataMisMatch',lit('Missing values at Target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconresult=[{\n",
    "#     \"SrcCount\":master_bulk_df_records,\n",
    "#     \"TargetCount\":GidCount[0][0],\n",
    "#     \"TrgtMissMatchCount\":df_MissingData.count()\n",
    "# }]\n",
    "\n",
    "# from pyspark.sql import Row\n",
    "# df_recon=sqlContext.createDataFrame(Row(**x) for x in reconresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_recon.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if  x == 'success':\n",
    "    update_progress(table_name,source,time_filter,records,start_time,starttime,'Success')\n",
    "    print('SUCCESS')\n",
    "else:\n",
    "    update_progress(table_name,source,time_filter,'0',start_time,starttime,'Failed')\n",
    "    print('FAILED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Customer Demogs ends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Customer Profile Begins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_str=['customer_code','mode_of_communication']\n",
    "cust_gc_df=load_gpdb_jdbc(col_str,\"customer_gc_genmst_customer\")\n",
    "# cust_gc_df=cust_gc_df.filter(col('mode_of_communication').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscPythonOptions = {\n",
    "         \"url\": prod_url,\n",
    "         \"user\": user_prod,\n",
    "         \"password\": pwd_prod,\n",
    "         \"dbschema\":\"staging\",\n",
    "         \"dbtable\": \"hni_customer_data\",\n",
    "         \"server.port\":\"1150-1170\"} \n",
    "\n",
    "# Get the data  from credit_bureau_data Table\n",
    "\n",
    "hni_df = sqlContext.read.format(\"greenplum\").options(**gscPythonOptions).load()\\\n",
    ".select('golden_id','hni_type').dropDuplicates().filter(col('hni_type').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_str=['txt_payer_customer_id','txt_payment_mode_cd']\n",
    "acc_gc_df=load_gpdb_jdbc(col_str,\"account_gc_acc_payment_entry\")\n",
    "acc_gc_df=acc_gc_df.filter(col('txt_payment_mode_cd').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1= master_bulk_df.join(cust_gc_df, trim(master_bulk_df.source_customer_id) == trim(cust_gc_df.customer_code), \"left\")\\\n",
    ".drop(cust_gc_df.customer_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2= df_1.join(hni_df, df_1.dc_unified_id == hni_df.golden_id, \"left\")\\\n",
    ".drop( hni_df.golden_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3= df_2.join(acc_gc_df, df_1.source_customer_id == acc_gc_df.txt_payer_customer_id, \"left\")\\\n",
    ".drop( acc_gc_df.txt_payer_customer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3=df_3.withColumn(\"service_level\",expr(\"case \\\n",
    "                    when hni_type = 'VIP CUSTOMER' then 5 when hni_type = 'PRIORITY CUSTOMER' then 5 \\\n",
    "                    else 1 end as service_level\")).alias(\"service_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_3.withColumnRenamed('dc_unified_id','golden_id').\\\n",
    "withColumnRenamed('mode_of_communication','communication_mode_preferred').\\\n",
    "withColumnRenamed('hni_type','customer_categorization').\\\n",
    "withColumnRenamed('txt_payment_mode_cd','payment_behaviour').\\\n",
    "withColumnRenamed('dc_action_date','last_updated')\\\n",
    ".withColumn('profile_json', to_json(lit(None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = df_3.select(col('golden_id').cast(IntegerType()),col('communication_mode_preferred').cast('string'),col('customer_categorization').cast('string'),col('service_level').cast(IntegerType()),col('payment_behaviour').cast('string'),col('last_updated').cast('timestamp'))\n",
    "df_main=df_main.withColumn('customer_type',lit(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "w1 = Window.partitionBy('golden_id').orderBy(F.col('last_updated').desc())\n",
    "df_main = df_main.withColumn('row_num',F.row_number().over(w1))\n",
    "df_main = df_main.filter('row_num == 1').drop( df_main.row_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.persist(pyspark.StorageLevel.MEMORY_AND_DISK)\n",
    "records=df_main.count()\n",
    "master_bulk_df.unpersist()\n",
    "records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main=df_main.select('golden_id', 'communication_mode_preferred', 'customer_categorization', 'service_level', 'payment_behaviour', 'last_updated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index = \"customer_profile_staging\"\n",
    "schema = \"customermart\"\n",
    "\n",
    "# records=df_main.count()\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    \n",
    "    df_main.write.option(\"truncate\", \"true\").format(\"greenplum\")\\\n",
    "    .option(\"dbtable\",output_index).option('dbschema',schema)\\\n",
    "    .option(\"server.port\",\"1150-1170\").option(\"url\",prod_url)\\\n",
    "    .option(\"user\", user_prod).option(\"password\",pwd_prod).mode('overwrite').save()\n",
    "\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    x = e\n",
    "    print(x)\n",
    "else:\n",
    "    x = 200 #success\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name='customer_profile'\n",
    "source='customer_profile'\n",
    "conn_prod = psycopg2.connect(host=prod_host, port=prod_port, user=user_prod, password=pwd_prod, dbname=prod_dbname)\n",
    "conn_to=conn_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generic update function which takes the records currently in temp table (created with prefix 1 to original customercoe table)\n",
    "# The function would first try to insert the records in original table. It that fails then it will upsert the records\n",
    "# Since there is no direct upsert query an update and insert query with where clause is used\n",
    "# This funciton just runs the SQL queries in GPDB and does not use spark\n",
    "\n",
    "def update(conn_to,table_name,source,gpdb_spark_options = prod_gpdb_spark_options,\n",
    "                  schema='customermart'):\n",
    "    conn_to.rollback()\n",
    "    primary_key = ['golden_id']\n",
    "    update_fields = ['communication_mode_preferred','customer_categorization','service_level', 'payment_behaviour','last_updated']\n",
    "    out_columns = ['golden_id','communication_mode_preferred','customer_categorization','service_level','payment_behaviour','last_updated']\n",
    "\n",
    "    cur_to = conn_to.cursor()  \n",
    "\n",
    "    only_insert_query = \"\"\"insert into {schema}.{table_name} ({out_columns}) select {out_columns} from \n",
    "    {schema}.{table_name}_staging \"\"\".format(schema=schema,table_name=table_name,out_columns = \",\".join(out_columns))\n",
    "    update_query = \"\"\"UPDATE {schema}.{table_name} orig\n",
    "                          SET\n",
    "                            {update_fields}\n",
    "                          FROM\n",
    "                            {schema}.{table_name}_staging temp\n",
    "                           WHERE \n",
    "                            {primary_key}\n",
    "                       \"\"\".format(schema=schema,table_name=table_name,primary_key= \" and \".join([ \"orig.{key} = temp.{key}\".format(key=key) for key in primary_key]),update_fields = \" , \".join([ \"{key} = temp.{key}\".format(key=key) for key in update_fields]))\n",
    "    insert_query = \"\"\" INSERT INTO {schema}.{table_name} ({out_columns})\n",
    "                           SELECT {out_columns}\n",
    "                           FROM\n",
    "                             {schema}.{table_name}_staging temp\n",
    "                           WHERE\n",
    "                             NOT EXISTS (\n",
    "                             SELECT 1 FROM {schema}.{table_name} orig WHERE \n",
    "                            {primary_key}\n",
    "                            )\n",
    "                        \"\"\".format(schema=schema,table_name=table_name,out_columns = \",\".join(out_columns),primary_key = \" and \".join([ \"orig.{key} = temp.{key}\".format(key=key) for key in primary_key]))\n",
    "\n",
    "    try:\n",
    "        print(\"Inside try segment\")\n",
    "        cur_to.execute(only_insert_query)\n",
    "        print(\"Executed Only insert query\")\n",
    "#         update_progress(table_name,source,time_filter,records)\n",
    "    except Exception as e:\n",
    "        print(\"Inside except segment\")\n",
    "        conn_to.rollback()\n",
    "        cur_to.execute(update_query)\n",
    "        print(\"Executed update query\")\n",
    "        cur_to.execute(insert_query)\n",
    "        print(\"Executed insert query\")\n",
    "#         update_progress(table_name,source,time_filter,records)\n",
    "    conn_to.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "try:\n",
    "    update(conn_to,table_name,source,prod_gpdb_spark_options, schema=\"customermart\")\n",
    "except Exception as e:\n",
    "    x = e\n",
    "    print(x)\n",
    "else:\n",
    "    x = 'success'\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if  x == 'success':\n",
    "    update_progress(table_name,source,time_filter,records,start_time,starttime,'Success')\n",
    "    print('SUCCESS')\n",
    "else:\n",
    "    update_progress(table_name,source,time_filter,'0',start_time,starttime,'Failed')\n",
    "    print('FAILED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Customer Profile Ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
